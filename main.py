# main.py
import tkinter as tk
from tkinter import ttk, messagebox
import threading
import pyaudio
import numpy as np
import time
import os
import sys

# å°è¯•å¯¼å…¥ faster-whisperï¼ˆæ‰“åŒ…åä¹Ÿèƒ½å·¥ä½œï¼‰
try:
    from faster_whisper import WhisperModel
    WHISPER_AVAILABLE = True
except Exception as e:
    WHISPER_AVAILABLE = False
    WHISPER_ERROR = str(e)

# æ£€æµ‹ GPU
GPU_AVAILABLE = False
try:
    import onnxruntime
    if 'CUDAExecutionProvider' in onnxruntime.get_available_providers():
        GPU_AVAILABLE = True
except:
    pass

# è·å–èµ„æºè·¯å¾„ï¼ˆå…¼å®¹æ‰“åŒ…åå’Œå¼€å‘ç¯å¢ƒï¼‰
def resource_path(relative_path):
    """è·å– PyInstaller æ‰“åŒ…åçš„èµ„æºè·¯å¾„"""
    try:
        # PyInstaller åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹ _MEIPASS
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath(".")
    return os.path.join(base_path, relative_path)

class VoiceFilterApp:
    def __init__(self, root):
        self.root = root
        self.root.title("æŠ–éŸ³ç›´æ’­æ•æ„Ÿè¯è¿‡æ»¤å™¨")
        self.root.geometry("480x420")
        self.root.resizable(False, False)
        
        self.is_running = False
        self.p = pyaudio.PyAudio()
        self.load_sensitive_words()
        self.model_sizes = self.discover_bundled_models()
        
        self.create_widgets()

    def load_sensitive_words(self):
        """åŠ è½½å†…ç½®æ•æ„Ÿè¯åº“"""
        self.sensitive_set = {"å¾®ä¿¡", "VX", "èµšé’±", "æœ€ä¾¿å®œ", "ç¨³èµš", " guaranteed", "ç»å¯¹", "ç¬¬ä¸€"}

    def discover_bundled_models(self):
        """è‡ªåŠ¨å‘ç°æ‰“åŒ…è¿›æ¥çš„æ¨¡å‹"""
        models_dir = resource_path("models")
        if not os.path.exists(models_dir):
            return ["base"]  # fallback
        
        available = []
        for model_name in ["base", "small", "medium"]:
            if os.path.isdir(os.path.join(models_dir, model_name)):
                available.append(model_name)
        return available if available else ["base"]

    def get_devices(self, kind='input'):
        devices = []
        for i in range(self.p.get_device_count()):
            dev = self.p.get_device_info_by_index(i)
            if kind == 'input' and dev['maxInputChannels'] > 0:
                devices.append((i, dev['name']))
            elif kind == 'output' and dev['maxOutputChannels'] > 0:
                devices.append((i, dev['name']))
        return devices

    def create_widgets(self):
        # æ ‡é¢˜
        title = tk.Label(self.root, text="æŠ–éŸ³ç›´æ’­æ•æ„Ÿè¯è¿‡æ»¤å™¨", font=("Arial", 14, "bold"))
        title.pack(pady=(10, 5))

        # Whisper çŠ¶æ€
        if not WHISPER_AVAILABLE:
            status = tk.Label(self.root, text=f"âŒ Whisper åŠ è½½å¤±è´¥: {WHISPER_ERROR}", fg="red")
            status.pack(pady=(0,10))
            return

        gpu_text = "âœ… æ£€æµ‹åˆ° NVIDIA GPU" if GPU_AVAILABLE else "âš ï¸ æœªæ£€æµ‹åˆ° NVIDIA GPUï¼ˆä½¿ç”¨ CPUï¼‰"
        tk.Label(self.root, text=gpu_text, fg="green" if GPU_AVAILABLE else "orange").pack()

        # è¾“å…¥è®¾å¤‡
        tk.Label(self.root, text="è¾“å…¥è®¾å¤‡ï¼ˆéº¦å…‹é£ï¼‰:", anchor='w').pack(fill='x', padx=20, pady=(10,0))
        input_devices = self.get_devices('input')
        self.input_names = [name for _, name in input_devices]
        self.input_idx_map = {name: idx for idx, name in input_devices}
        self.input_combo = ttk.Combobox(self.root, values=self.input_names, state="readonly")
        if self.input_names:
            self.input_combo.current(0)
        self.input_combo.pack(fill='x', padx=20, pady=5)

        # è¾“å‡ºè®¾å¤‡ï¼ˆä¼˜å…ˆ VB-Cableï¼‰
        tk.Label(self.root, text="è¾“å‡ºè®¾å¤‡ï¼ˆæ¨è VB-Cableï¼‰:", anchor='w').pack(fill='x', padx=20, pady=(10,0))
        output_devices = self.get_devices('output')
        vb_devices = [name for _, name in output_devices if 'CABLE' in name.upper()]
        if not vb_devices:
            vb_devices = [name for _, name in output_devices]
        self.output_names = vb_devices
        self.output_idx_map = {name: idx for idx, name in output_devices}
        self.output_combo = ttk.Combobox(self.root, values=self.output_names, state="readonly")
        if self.output_names:
            self.output_combo.current(0)
        self.output_combo.pack(fill='x', padx=20, pady=5)

        # æ¨¡å‹é€‰æ‹©
        tk.Label(self.root, text="Whisper æ¨¡å‹:", anchor='w').pack(fill='x', padx=20, pady=(10,0))
        self.model_var = tk.StringVar(value=self.model_sizes[0])
        model_combo = ttk.Combobox(self.root, textvariable=self.model_var, values=self.model_sizes, state="readonly")
        model_combo.pack(fill='x', padx=20, pady=5)
        model_tip = "â€¢ base: ä½å»¶è¿Ÿï¼Œé€‚åˆ CPU\nâ€¢ small: æ›´å‡†ç¡®ï¼Œæ¨è GPU"
        tk.Label(self.root, text=model_tip, fg="gray", justify='left').pack(anchor='w', padx=20)

        # å¯åŠ¨æŒ‰é’®
        btn_frame = tk.Frame(self.root)
        btn_frame.pack(pady=20)
        self.start_btn = tk.Button(btn_frame, text="â–¶ å¯åŠ¨è¿‡æ»¤", command=self.toggle_process, width=15, height=2)
        self.start_btn.pack()

        # åº•éƒ¨æç¤º
        hint = tk.Label(self.root, text="ä½¿ç”¨å‰è¯·å®‰è£… VB-Cable\nç›´æ’­ä¼´ä¾£ä¸­é€‰æ‹© 'CABLE Input' ä½œä¸ºéº¦å…‹é£", fg="gray")
        hint.pack(side='bottom', pady=(0,10))

    def toggle_process(self):
        if not self.is_running:
            self.start_process()
        else:
            self.stop_process()

    def start_process(self):
        try:
            input_name = self.input_combo.get()
            output_name = self.output_combo.get()
            if not input_name or not output_name:
                messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©è¾“å…¥å’Œè¾“å‡ºè®¾å¤‡")
                return

            self.input_idx = self.input_idx_map[input_name]
            self.output_idx = self.output_idx_map[output_name]
            self.selected_model = self.model_var.get()

            self.is_running = True
            self.start_btn.config(text="â¹ åœæ­¢è¿‡æ»¤", state='disabled')
            self.process_thread = threading.Thread(target=self.run_filter, daemon=True)
            self.process_thread.start()
            
            # å¼‚æ­¥å¯ç”¨æŒ‰é’®ï¼ˆé¿å…å¡æ­»ï¼‰
            self.root.after(1000, lambda: self.start_btn.config(state='normal'))
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯åŠ¨å¤±è´¥:\n{str(e)}")
            self.is_running = False

    def run_filter(self):
        try:
            # === åŠ è½½å†…ç½® Whisper æ¨¡å‹ ===
            model_path = resource_path(os.path.join("models", self.selected_model))
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"æ¨¡å‹æœªæ‰¾åˆ°: {model_path}")

            device = "cuda" if GPU_AVAILABLE else "cpu"
            compute_type = "float16" if GPU_AVAILABLE else "int8"
            model = WhisperModel(model_path, device=device, compute_type=compute_type)

            # === éŸ³é¢‘å‚æ•° ===
            INPUT_RATE = 16000   # Whisper æœ€ä½³è¾“å…¥
            OUTPUT_RATE = 48000  # VB-Cable å…¼å®¹ç‡
            CHUNK = 1024
            CHANNELS = 1

            # === æ‰“å¼€éŸ³é¢‘æµ ===
            stream_in = self.p.open(
                format=pyaudio.paFloat32,
                channels=CHANNELS,
                rate=INPUT_RATE,
                input=True,
                input_device_index=self.input_idx,
                frames_per_buffer=CHUNK
            )

            stream_out = self.p.open(
                format=pyaudio.paFloat32,
                channels=2,  # ç«‹ä½“å£°ï¼ˆç›´æ’­ä¼´ä¾£æ›´å…¼å®¹ï¼‰
                rate=OUTPUT_RATE,
                output=True,
                output_device_index=self.output_idx,
                frames_per_buffer=CHUNK * 3  # 16k â†’ 48k
            )

            # === ç¼“å†²ä¸çŠ¶æ€ ===
            audio_buffer = np.array([], dtype=np.float32)
            last_process_time = time.time()
            mute_intervals = []  # [(global_start_time, global_end_time), ...]

            while self.is_running:
                try:
                    # è¯»å–éŸ³é¢‘å—
                    data = stream_in.read(CHUNK, exception_on_overflow=False)
                    chunk_audio = np.frombuffer(data, dtype=np.float32)
                    audio_buffer = np.concatenate([audio_buffer, chunk_audio])

                    # æ¯ 1.2 ç§’å¤„ç†ä¸€æ¬¡
                    if len(audio_buffer) >= int(1.2 * INPUT_RATE) and (time.time() - last_process_time) > 1.0:
                        # è¯†åˆ«
                        segments, _ = model.transcribe(
                            audio_buffer,
                            language="zh",
                            word_timestamps=True,
                            initial_prompt="ä¸­æ–‡è¯­éŸ³è¯†åˆ«"
                        )

                        # æ£€æŸ¥æ•æ„Ÿè¯
                        buffer_start_time = time.time() - 1.2
                        for segment in segments:
                            for word in segment.words:
                                clean_word = word.word.strip(" ,.!?ï¼Œã€‚ï¼ï¼Ÿ")
                                if clean_word in self.sensitive_set:
                                    global_start = buffer_start_time + word.start
                                    global_end = buffer_start_time + word.end
                                    mute_intervals.append((global_start, global_end))
                                    print(f"ğŸ”‡ å±è”½: '{clean_word}' [{word.start:.2f}-{word.end:.2f}s]")

                        # æ¸…ç©ºç¼“å†²
                        audio_buffer = np.array([], dtype=np.float32)
                        last_process_time = time.time()

                    # === è¾“å‡ºéŸ³é¢‘ï¼ˆå¸¦é™éŸ³ï¼‰===
                    current_time = time.time()
                    
                    # æ¸…ç†è¿‡æœŸé™éŸ³åŒºé—´
                    mute_intervals = [(s, e) for s, e in mute_intervals if e > current_time]
                    
                    # æ£€æŸ¥å½“å‰æ˜¯å¦éœ€é™éŸ³
                    should_mute = any(s <= current_time <= e for s, e in mute_intervals)

                    # ç®€å•é‡é‡‡æ ·: 16k â†’ 48k (é‡å¤é‡‡æ ·)
                    upsampled = np.repeat(chunk_audio, 3)
                    stereo_audio = np.column_stack((upsampled, upsampled))  # è½¬ç«‹ä½“å£°

                    if should_mute:
                        stereo_audio = np.zeros_like(stereo_audio)

                    stream_out.write(stereo_audio.astype(np.float32).tobytes())

                except Exception as e:
                    print(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                    break

            # æ¸…ç†
            stream_in.stop_stream()
            stream_in.close()
            stream_out.stop_stream()
            stream_out.close()

        except Exception as e:
            print(f"ä¸»æµç¨‹é”™è¯¯: {e}")
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"å¤„ç†å¼‚å¸¸:\n{str(e)}"))

        finally:
            self.is_running = False
            self.root.after(0, lambda: self.start_btn.config(text="â–¶ å¯åŠ¨è¿‡æ»¤"))

    def stop_process(self):
        self.is_running = False

    def on_closing(self):
        if self.is_running:
            self.stop_process()
            # ç­‰å¾…çº¿ç¨‹ç»“æŸï¼ˆæœ€å¤š2ç§’ï¼‰
            if self.process_thread and self.process_thread.is_alive():
                self.process_thread.join(timeout=2.0)
        self.p.terminate()
        self.root.destroy()

if __name__ == "__main__":
    root = tk.Tk()
    app = VoiceFilterApp(root)
    root.protocol("WM_DELETE_WINDOW", app.on_closing)
    root.mainloop()