# run.py
import tkinter as tk
from tkinter import ttk, messagebox
from tkinter import font as tkFont
import threading
import pyaudio
from multiprocessing import Process, Queue, Event 
from util import get_logger
import time
import os
import sys
import torch 
import cv2
from filterprocess import (
    process_capture_audio,
    process_send_audio_frames,
    process_capture_video_frames,
    process_send_video_frames,
    init_audio_mic,
    init_audio_output,
    init_video_cam
)
from util import  load_sensitive_words, AudioReplaceType



 
# å°è¯•å¯¼å…¥ faster-whisperï¼ˆæ‰“åŒ…åä¹Ÿèƒ½å·¥ä½œï¼‰
try:
    WHISPER_AVAILABLE = True
except Exception as e:
    WHISPER_AVAILABLE = False
    WHISPER_ERROR = str(e)

# æ£€æµ‹ GPU
try:
    CUDA_AVAILABLE = torch.cuda.is_available()
except ImportError:
    CUDA_AVAILABLE = False

# æ·»åŠ OpenCVå¯¼å…¥ç”¨äºè§†é¢‘å¤„ç†
try:
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
 
logger = get_logger()

stop_event =  Event() 
font_name = None

# è·å–èµ„æºè·¯å¾„ï¼ˆå…¼å®¹æ‰“åŒ…åå’Œå¼€å‘ç¯å¢ƒï¼‰
def resource_path(relative_path):
    try:
        # PyInstaller åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹ _MEIPASS
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath(".")
    return os.path.join(base_path, relative_path)
 
class VoiceFilterApp:
    def __init__(self, root):
        self.root = root
        self.root.title("æ¶ˆç¦è…¾")

        # Calculate new dimensions: increase height by 20%
        original_height = 550
        new_height = int(original_height * 1.2)  # 660 pixels
        x = (self.root.winfo_screenwidth() // 2) - (480 // 2)
        y = (self.root.winfo_screenheight() // 2) - (new_height // 2)  # Adjusted for new height
        self.root.geometry(f"480x{new_height}+{x}+{y}")  # Updated geometry
        
        # self.root.geometry(f"480x{new_height}")  # Changed from 480x550 to 480x660
        self.root.resizable(False, False)
        
        # Set window icon
        try:
            icon_path = resource_path("res/favicon.ico")
            if os.path.exists(icon_path):
                self.root.iconbitmap(icon_path)
        except Exception as e:
            logger.warning(f"Failed to load icon: {e}")
        
        # Show loading message immediately
        self.loading_label = tk.Label(root, text="ç³»ç»Ÿåˆå§‹åŒ–ä¸­...", font=("", 14))
        self.loading_label.pack(expand=True)
        self.root.update_idletasks()
        self.root.update()  # Force the window to display the loading message
        
        logger.info("Voice Filter App started")
        if CUDA_AVAILABLE:
            logger.info(f"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}")
        else:
            logger.info("CUDA is not available. Using CPU.")
        
        self.is_running = False
        self.caption_running = False
        self.whisper_running = False

        self.audio_processes = None
        self.video_processes = None
        self.process_thread = None

        self.p = pyaudio.PyAudio()
     
        # Add mute option variable
        self.mute_option = tk.StringVar(value="silence")  # Default to silence
        self.loading_label.destroy()
        self.create_widgets()
        

    def get_devices(self, kind='input'):
        devices = []
        for i in range(self.p.get_device_count()):
            dev = self.p.get_device_info_by_index(i)
      
            if kind == 'input' and dev['maxInputChannels'] > 0:
                tmp_d = init_audio_mic(i,self.p)
                if tmp_d:
                    tmp_d.close()
                    devices.append((i, dev['name']))
            elif kind == 'output' and dev['maxOutputChannels'] > 0:
                devices.append((i, dev['name']))
        return devices

    # æ·»åŠ æ‘„åƒå¤´æ£€æµ‹æ–¹æ³•
    def get_camera_devices(self):
        """æ£€æµ‹å¯ç”¨çš„æ‘„åƒå¤´è®¾å¤‡"""
        if not CV2_AVAILABLE:
            return []
            
        cameras = []
        cameras = self.get_camera_devices_windows()
        if cameras:  # å¦‚æœæœ‰æ‘„åƒå¤´ï¼Œåˆ™è¿”å›
            return cameras
        for i in range(10):  # æ£€æµ‹å‰10ä¸ªæ‘„åƒå¤´
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                ret, _ = cap.read()
                if ret:
                    cameras.append((i, f"æ‘„åƒå¤´ {i}"))
                cap.release()
        return cameras
    
    def get_camera_devices_windows(self):
        # 1. ç”¨ pygrabber è·å–çœŸå®åç§°åˆ—è¡¨ï¼ˆåŸºäº DirectShowï¼‰
        try:
            from pygrabber.dshow_graph import FilterGraph
            device_names = FilterGraph().get_input_devices()
        except Exception as e:
            logger.error("Failed to get camera names:", e)
            device_names = []

        cameras = []
        # 2. ç”¨ CAP_DSHOW åç«¯é€ä¸ªæµ‹è¯•
        for i in range(len(device_names)):
            cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
            if cap.isOpened():
                ret, frame = cap.read()
                name = device_names[i] if i < len(device_names) else f"Unknown Camera {i}"
                if ret and frame is not None and frame.size > 0:
                    cameras.append((i, name))
                cap.release()
        return cameras

    # æ–°å¢å‡½æ•°ï¼šè·å–æ‘„åƒå¤´æ”¯æŒçš„åˆ†è¾¨ç‡å’ŒFPS
    def get_camera_formats(self, device_index):
        """è·å–æŒ‡å®šæ‘„åƒå¤´æ”¯æŒçš„åˆ†è¾¨ç‡å’ŒFPS"""
        try:
            from pygrabber.dshow_graph import FilterGraph
            graph = FilterGraph()
            devices = graph.get_input_devices()
            
            if device_index >= len(devices):
                return []
                
            # è®¾ç½®è¯¥è®¾å¤‡ä¸ºå½“å‰è¾“å…¥æº
            graph.add_video_input_device(device_index)
            
            # è·å–è¯¥è®¾å¤‡æ”¯æŒçš„æ‰€æœ‰æ ¼å¼
            formats = graph.get_input_device().get_formats()
            # æå–å”¯ä¸€çš„åˆ†è¾¨ç‡å’ŒFPSç»„åˆ
            device_info = set()
            fps = 0
            for fmt in formats:
                width = fmt.get('width', 0)
                height = fmt.get('height', 0)
                fps = fmt.get('max_framerate', 30)
                device_info.add( 
                        f"{width}x{height}"
                     )
            # è¿”å›å»é‡åçš„æ ¼å¼åˆ—è¡¨
            # ä¿®æ”¹:æŒ‰åˆ†è¾¨ç‡ä»å¤§åˆ°å°æ’åº
            sorted_resolutions = sorted(list(device_info), key=lambda x: int(x.split('x')[0]) * int(x.split('x')[1]), reverse=True)
            return sorted_resolutions, int(fps)
        except Exception as e:
            logger.error(f"Failed to get camera formats: {e}")
            return []

    def create_widgets(self):
        # Clear any existing widgets (in case of reload)
        for widget in self.root.winfo_children():
            widget.destroy()
        text = "\u2009".join("æ¶ˆç¦è…¾")    
        # Title
        title = tk.Label(self.root, text=text, font=(font_name, 14 ))
        title.pack(pady=(10, 5))

        if not WHISPER_AVAILABLE:
            status = tk.Label(self.root, text=f"âŒ Whisper åŠ è½½å¤±è´¥: {WHISPER_ERROR}", fg="red")
            status.pack(pady=(0,10))
            return

        device_info = "âœ… ä½¿ç”¨ GPU è¿›è¡Œè¯­éŸ³è¯†åˆ«" if CUDA_AVAILABLE else "âš ï¸ ä½¿ç”¨ CPU è¿›è¡Œè¯­éŸ³è¯†åˆ«"
        color = "green" if CUDA_AVAILABLE else "orange"
        tk.Label(self.root, text=device_info, fg=color).pack()

        # è¾“å…¥è®¾å¤‡
        tk.Label(self.root, text="è¾“å…¥è®¾å¤‡ï¼ˆéº¦å…‹é£ï¼‰:", anchor='w').pack(fill='x', padx=20, pady=(10,0))
        input_devices = self.get_devices('input')
        self.input_names = [f"{i}_{name}" for i, name in input_devices]
        self.input_idx_map = {f"{idx}_{name}": idx for idx, name in input_devices}
        self.input_combo = ttk.Combobox(self.root, values=self.input_names, state="readonly")
        if self.input_names:
            self.input_combo.current(0)
        self.input_combo.pack(fill='x', padx=20, pady=5)

        # è¾“å‡ºè®¾å¤‡ï¼ˆä¼˜å…ˆ VB-Cableï¼‰
        tk.Label(self.root, text="è¾“å‡ºè®¾å¤‡ï¼ˆæ¨è VB-Cableï¼‰:", anchor='w').pack(fill='x', padx=20, pady=(10,0))
        output_devices = self.get_devices('output')
        vb_devices = [name for _, name in output_devices if 'CABLE' in name.upper()]
        if not vb_devices:
            vb_devices = [name for _, name in output_devices]
        self.output_names = vb_devices
        self.output_idx_map = {name: idx for idx, name in output_devices}
        self.output_combo = ttk.Combobox(self.root, values=self.output_names, state="readonly")
        if self.output_names:
            self.output_combo.current(0)
        self.output_combo.pack(fill='x', padx=20, pady=5)

        # è§†é¢‘è¾“å…¥è®¾å¤‡é€‰æ‹©ï¼ˆæ–°å¢ï¼‰
        if CV2_AVAILABLE:
            tk.Label(self.root, text="è§†é¢‘è¾“å…¥è®¾å¤‡:", anchor='w').pack(fill='x', padx=20, pady=(10,0))
            camera_devices = self.get_camera_devices()
            self.camera_names = [name for _, name in camera_devices]
            self.camera_idx_map = {name: idx for idx, name in camera_devices}
            self.camera_combo = ttk.Combobox(self.root, values=self.camera_names, state="readonly")
            if self.camera_names:
                self.camera_combo.current(0)
                # ç»‘å®šé€‰æ‹©äº‹ä»¶ï¼Œå½“é€‰ä¸­æ‘„åƒå¤´æ—¶æ›´æ–°åˆ†è¾¨ç‡é€‰é¡¹
                self.camera_combo.bind('<<ComboboxSelected>>', self.on_camera_selected)
            self.camera_combo.pack(fill='x', padx=20, pady=5)
            
            # è§†é¢‘åˆ†è¾¨ç‡å’ŒFPSé€‰æ‹©ï¼ˆæ‹†åˆ†ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„ä¸‹æ‹‰æ¡†ï¼‰
            tk.Label(self.root, text="è§†é¢‘åˆ†è¾¨ç‡:", anchor='w').pack(fill='x', padx=20, pady=(10,0))
            self.resolution_combo = ttk.Combobox(self.root, state="readonly")
            self.resolution_combo.pack(fill='x', padx=20, pady=5)
            
            tk.Label(self.root, text="è§†é¢‘FPS:", anchor='w').pack(fill='x', padx=20, pady=(10,0))
            self.fps_combo = ttk.Combobox(self.root, state="readonly")
            self.fps_combo.pack(fill='x', padx=20, pady=5)
            
            # åˆå§‹åŒ–åˆ†è¾¨ç‡å’ŒFPSé€‰é¡¹
            if self.camera_names:
                self.update_resolution_options(0)
 

        # æ·»åŠ æ¶ˆéŸ³é€‰é¡¹åŒºåŸŸ
        tk.Label(self.root, text="æ¶ˆéŸ³é€‰é¡¹:", anchor='w').pack(fill='x', padx=20, pady=(10, 0))
       
        # ä¿®æ”¹ä¸ºä¸‹æ‹‰æ¡†é€‰æ‹©æ–¹å¼ï¼Œä½¿ç”¨æ›´å‹å¥½çš„æ˜¾ç¤ºæ–‡å­—
        mute_options_display = ["ä½¿ç”¨é™éŸ³ä»£æ›¿", "ä½¿ç”¨'å“”'ä»£æ›¿"]
        mute_options_values = [AudioReplaceType.SILENCE.value, AudioReplaceType.BEEP.value]
        self.mute_option_combo = ttk.Combobox(self.root, values=mute_options_display, state="readonly")

        self.mute_option_combo.set("ä½¿ç”¨é™éŸ³ä»£æ›¿")  # é»˜è®¤å€¼
        self.mute_option_combo.pack(fill='x', padx=20, pady=5)
        
        # åˆ›å»ºæ˜ å°„å­—å…¸ï¼Œç”¨äºè·å–å®é™…å€¼
        self.mute_option_map = dict(zip(mute_options_display, mute_options_values))
        
        # æ·»åŠ å¯¼å…¥æ•æ„Ÿè¯æŒ‰é’®å’Œå¯åŠ¨è¿‡æ»¤æŒ‰é’®ï¼Œæ°´å¹³æ’åˆ—
        buttons_frame = tk.Frame(self.root)
        buttons_frame.pack(pady=10)
        
        self.start_btn = tk.Button(buttons_frame, text="â–¶ å¯åŠ¨è¿‡æ»¤", command=self.toggle_process, width=15, height=2)
        self.start_btn.pack(side=tk.LEFT, padx=(5, 0))

        # çŠ¶æ€æ 
        self.status_frame = tk.Frame(self.root)
        self.status_frame.pack(pady=5)
        
        self.mic_status = tk.Label(self.status_frame, text="ğŸ¤ éº¦å…‹é£: æœªè¿æ¥", fg="gray")
        self.mic_status.pack(side=tk.LEFT, padx=5)
        
        self.filter_status = tk.Label(self.status_frame, text="ğŸ” è¿‡æ»¤: æœªè¿è¡Œ", fg="gray")
        self.filter_status.pack(side=tk.LEFT, padx=5)
        
        self.cable_status = tk.Label(self.status_frame, text="ğŸ”Œ Cable: æœªæ£€æµ‹", fg="gray")
        self.cable_status.pack(side=tk.LEFT, padx=5)
        
        # è§†é¢‘çŠ¶æ€ï¼ˆæ–°å¢ï¼‰
        if CV2_AVAILABLE:
            self.video_status = tk.Label(self.status_frame, text="ğŸ“¹ è§†é¢‘: æœªè¿è¡Œ", fg="gray")
            self.video_status.pack(side=tk.LEFT, padx=5)

        # åº•éƒ¨æç¤º
        hint = tk.Label(self.root, text="ä½¿ç”¨å‰è¯·å®‰è£… VB-Cable\nç›´æ’­è½¯ä»¶ä¸­é€‰æ‹© 'CABLE Input' ä½œä¸ºéº¦å…‹é£", fg="gray")
        hint.pack(side='bottom', pady=(0,10))
    def toggle_process(self):
        if not self.is_running:
            self.start_process()
        else:
            self.stop_process()
    def start_process(self):
        # å ä½å‡½æ•°ï¼šå¯åŠ¨å¤„ç†æµç¨‹
        try:
            input_name = self.input_combo.get()
            output_name = self.output_combo.get()
            if not input_name or not output_name:
                messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©è¾“å…¥å’Œè¾“å‡ºè®¾å¤‡")
                logger.error("Input or output device not selected")
                return

            self.input_idx = self.input_idx_map[input_name]
            self.output_idx = self.output_idx_map[output_name]
            
            # Output all selected device indices
            logger.info(f"Selected input device index: {self.input_idx}")
            logger.info(f"Selected output device index: {self.output_idx}")
            
            # If video is available and enabled, log camera device index
            if CV2_AVAILABLE  and self.camera_names:
                camera_name = self.camera_combo.get()
                if camera_name:
                    self.camera_idx = self.camera_idx_map[camera_name]
                    logger.info(f"Selected camera device index: {self.camera_idx}")
            
            logger.info(f"Starting process with input: {input_name}, output: {output_name},  ")

            # æ›´æ–°Cableè¾“å‡ºçŠ¶æ€
            cable_detected = 'CABLE' in output_name.upper()
            self.cable_status.config(text=f"{'âœ…' if cable_detected else 'âŒ'} Cable: {'å·²æ£€æµ‹' if cable_detected else 'æœªæ£€æµ‹'}", 
                                     fg="green" if cable_detected else "red")

            self.is_running = True
            stop_event.clear()
            self.start_btn.config(text="â¹ åœæ­¢è¿‡æ»¤", state='disabled')
            
            # æ›´æ–°è¿‡æ»¤çŠ¶æ€
            self.filter_status.config(text="ğŸ” è¿‡æ»¤: åˆå§‹åŒ–...", fg="orange")
            
            # å¯åŠ¨å¤„ç†çº¿ç¨‹
            self.process_thread = threading.Thread(target=self.run_filter, daemon=True)
            self.process_thread.start()
            
            # å¼‚æ­¥å¯ç”¨æŒ‰é’®ï¼ˆé¿å…å¡æ­»ï¼‰
            self.root.after(1000, lambda: self.start_btn.config(state='normal'))
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯åŠ¨å¤±è´¥:\n{str(e)}")
            logger.error(f"Failed to start process: {str(e)}")
            self.is_running = False
            stop_event.set()

    def stop_process(self):
        # å ä½å‡½æ•°ï¼šåœæ­¢å¤„ç†æµç¨‹
        self.is_running = False
        # Also update the is_running flag in claude_plan module
        stop_event.set()
        logger.info("Stop process requested")
        # Update button to show stopping state
        self.start_btn.config(state='disabled', text="â¹ åœæ­¢ä¸­...", fg="gray")
        
        while (self.whisper_running or self.caption_running) :
            logger.info("Waiting for threads to finish...")
            self.root.update()  # Keep UI responsive
            time.sleep(0.1)
            
        # Reset button to initial state
        self.start_btn.config(text="â–¶ å¯åŠ¨è¿‡æ»¤", state='normal', fg="black")
        logger.info("Process stopped")

    def check_device_available(self,audio_input_device_index, camera_idx,w,h,fps):
        audio_input = init_audio_mic(audio_input_device_index,self.p)
        audio_output = init_audio_output(self.p)
        cam = init_video_cam(camera_idx,w,h,fps)
        msg = None
        ret = True
        if audio_input is None:
            msg = 'éŸ³é¢‘è¾“å…¥è®¾å¤‡æ£€æµ‹å¤±è´¥'
            ret = False
            logger.error(msg)
        else:
            logger.info("éŸ³é¢‘è¾“å…¥è®¾å¤‡æ£€æµ‹æˆåŠŸ")
            audio_input.close()
        if audio_output is None:
            msg = 'éŸ³é¢‘è¾“å‡ºè®¾å¤‡æ£€æµ‹å¤±è´¥'
            ret = False
            logger.error(msg)
        else:
            logger.info("éŸ³é¢‘è¾“å‡ºè®¾å¤‡æ£€æµ‹æˆåŠŸ")
            audio_output.close()
        if cam is None:
            msg = 'è§†é¢‘è¾“å…¥è®¾å¤‡æ£€æµ‹å¤±è´¥'
            ret = False
            logger.error("è§†é¢‘è¾“å…¥è®¾å¤‡æ£€æµ‹å¤±è´¥")
        else:
            logger.info("è§†é¢‘è¾“å…¥è®¾å¤‡æ£€æµ‹æˆåŠŸ")
            if cam.isOpened():  # Check if the video capture is open
                cam.release()
      
        return ret, msg

    def run_filter(self):
        logger.info(f"self.input_idx_map : {self.input_idx_map}")
        audio_input_device_index = self.input_idx_map[self.input_combo.get()]
        logger.info(f"audio_input_device_indexï¼š{self.input_idx_map[self.input_combo.get()]}")
        # è·å–é€‰ä¸­çš„åˆ†è¾¨ç‡å­—ç¬¦ä¸² (ä¾‹å¦‚: "640x480")
        selected_resolution = self.resolution_combo.get()
        logger.info(f"selected_resolution: {selected_resolution}")
        if 'x' in selected_resolution:
            width, height = map(int, selected_resolution.split('x'))
        else:
            width, height = 640, 480
        # è·å–é€‰ä¸­çš„FPSå­—ç¬¦ä¸² (ä¾‹å¦‚: "30")
        selected_fps = self.fps_combo.get()
        logger.info(f"selected_fps: {selected_fps}")
        
        # check device available
        ret, msg = self.check_device_available(audio_input_device_index, self.camera_idx_map[self.camera_combo.get()], width, height ,int(selected_fps))
        if not ret:
            messagebox.showerror("é”™è¯¯", msg)
            # Update UI status
            self.start_btn.config(text="â–¶ å¯åŠ¨è¿‡æ»¤", state='normal')
            self.mic_status.config(text="ğŸ¤ éº¦å…‹é£: æœªè¿æ¥", fg="gray")
            self.filter_status.config(text="ğŸ” è¿‡æ»¤: æœªè¿è¡Œ", fg="gray")
            if CV2_AVAILABLE:
                self.video_status.config(text="ğŸ“¹ è§†é¢‘: æœªè¿è¡Œ", fg="gray")
            self.is_running = False
            return
              
        # åˆå§‹åŒ–é˜Ÿåˆ—
        self.audio_queue = Queue()
        video_queue = Queue()  # Changed to PriorityQueue for better ordering
        audio_queue = Queue()
        record_queue = Queue()
        # Reset the is_running flag in claude_plan before starting threads
        stop_event.clear()
        start_time = time.time() + 10.0
        # åˆ›å»ºæ•æ„Ÿè¯é›†åˆ
        sensitive_set = load_sensitive_words()
        logger.info(f"load sensitive words success,words size : {len(sensitive_set)}")
        # åˆ›å»ºéŸ³é¢‘å¤„ç†è¿›ç¨‹ï¼Œä½¿ç”¨ä»claude_planå¯¼å…¥çš„å‡½æ•°
        self.audio_processes = []
        # è·å–é€‰ä¸­çš„æ¶ˆéŸ³é€‰é¡¹
        selected_mute_display = self.mute_option_combo.get()
        selected_mute_option = self.mute_option_map.get(selected_mute_display, "silence")
        logger.info(f"Selected mute option: {selected_mute_option}")
        
        # åœ¨åˆ›å»ºè¿›ç¨‹æ—¶ä¼ é€’æ¶ˆéŸ³é€‰é¡¹å‚æ•°
        capture_audio_process = Process(target=process_capture_audio, name="AudioCapture",
                                        args=(audio_queue,record_queue, start_time, stop_event, audio_input_device_index, 
                                                sensitive_set, self.mute_option_map[self.mute_option_combo.get()] ))
        send_audio_process = Process(target=process_send_audio_frames, name="AudioProcessor",args=(audio_queue, start_time, stop_event ) )

        self.audio_processes.extend([capture_audio_process, send_audio_process])
        # å¯åŠ¨è§†é¢‘è¿›ç¨‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        for process in self.audio_processes:
            logger.info(f"Starting audio process: {process.name}")
            process.start()
        # å¦‚æœå¯ç”¨äº†è§†é¢‘åŠŸèƒ½ï¼Œåˆ™åˆ›å»ºè§†é¢‘å¤„ç†è¿›ç¨‹
        self.video_processes = []
        if CV2_AVAILABLE :
            capture_video_process = Process(target=process_capture_video_frames, name="VideoCapture",args=(video_queue, start_time, stop_event,self.camera_idx_map[self.camera_combo.get()], width, height,int(selected_fps)))
            send_video_process = Process(target=process_send_video_frames, name="VideoSender",args=(video_queue, start_time, stop_event, width, height,int(selected_fps)))
            self.video_processes.extend([capture_video_process, send_video_process])
            # æ›´æ–°è§†é¢‘çŠ¶æ€
            self.video_status.config(text="ğŸ“¹ è§†é¢‘: è¿è¡Œä¸­", fg="green")
        
        # æ›´æ–°çŠ¶æ€
        self.mic_status.config(text="ğŸ¤ éº¦å…‹é£: è¿è¡Œä¸­", fg="green")
        self.filter_status.config(text="ğŸ” è¿‡æ»¤: è¿è¡Œä¸­", fg="green")
        
        # å¯åŠ¨è§†é¢‘è¿›ç¨‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        for process in self.video_processes:
            logger.info(f"Starting video process: {process.name}")
            process.start()
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        try:
            while self.is_running  :
                time.sleep(0.1)
            for process in self.video_processes:
                logger.warning(f"Terminating stuck process: {process.name}")
                if process is not None and  process.is_alive():  # ç¡®ä¿è¿›ç¨‹å·²å¯åŠ¨
                    process.terminate()
                    process.join(timeout=1.0)
                    if process.is_alive():  # ç¡®ä¿è¿›ç¨‹å·²ç»ˆæ­¢
                        logger.error(f"Failed to terminate process: {process.name}")
            for process in self.audio_processes:
                logger.warning(f"Terminating stuck process: {process.name}")
                if process is not None and  process.is_alive():  # ç¡®ä¿è¿›ç¨‹å·²å¯åŠ¨
                    process.terminate()
                    process.join(timeout=1.0)
                    if process.is_alive():  # ç¡®ä¿è¿›ç¨‹å·²ç»ˆæ­¢
                        logger.error(f"Failed to terminate process: {process.name}")
        except Exception as e:
            logger.info("Interrupted by user, stopping processes...")
            self.is_running = False
            
            # ç­‰å¾…è¿›ç¨‹ç»“æŸ
            capture_audio_process.join()
            send_audio_process.join()
            for process in self.video_processes:
                process.join()
        
        # æ›´æ–°çŠ¶æ€
        self.mic_status.config(text="ğŸ¤ éº¦å…‹é£: å·²åœæ­¢", fg="gray")
        self.filter_status.config(text="ğŸ” è¿‡æ»¤: å·²åœæ­¢", fg="gray")
        if CV2_AVAILABLE:
            self.video_status.config(text="ğŸ“¹ è§†é¢‘: å·²åœæ­¢", fg="gray")
        
        logger.info("Audio processing shutdown complete")

 
    def on_closing(self):
        # å ä½å‡½æ•°ï¼šå…³é—­åº”ç”¨æ—¶çš„æ¸…ç†æ“ä½œ
        if self.is_running:
            self.stop_process()
            # ç­‰å¾…çº¿ç¨‹ç»“æŸï¼ˆæœ€å¤š2ç§’ï¼‰
        if self.process_thread and self.process_thread.is_alive():
            self.process_thread.join(timeout=2.0)
        if self.video_processes:
            for process in self.video_processes:
                logger.warning(f"Terminating stuck process: {process.name}")
                if process is not None and  process.is_alive():  # ç¡®ä¿è¿›ç¨‹å·²å¯åŠ¨
                    process.terminate()
                    process.join(timeout=1.0)
                    if process.is_alive():  # ç¡®ä¿è¿›ç¨‹å·²ç»ˆæ­¢
                        logger.error(f"Failed to terminate process: {process.name}")
        if self.audio_processes:
            for process in self.audio_processes:
                logger.warning(f"Terminating stuck process: {process.name}")
                if process is not None and  process.is_alive():  # ç¡®ä¿è¿›ç¨‹å·²å¯åŠ¨
                    process.terminate()
                    process.join(timeout=1.0)
                    if process.is_alive():  # ç¡®ä¿è¿›ç¨‹å·²ç»ˆæ­¢
                        logger.error(f"Failed to terminate process: {process.name}")
            
        if self.p:
            self.p.terminate()
        self.root.destroy()
        logger.info("Application closed")

    def on_camera_selected(self, event=None):
        """å½“é€‰æ‹©æ‘„åƒå¤´æ—¶æ›´æ–°åˆ†è¾¨ç‡å’ŒFPSé€‰é¡¹"""
        camera_name = self.camera_combo.get()
        if camera_name in self.camera_idx_map:
            camera_index = self.camera_idx_map[camera_name]
            self.update_resolution_options(camera_index)
    
    def update_resolution_options(self, camera_index):
        """æ›´æ–°æŒ‡å®šæ‘„åƒå¤´çš„åˆ†è¾¨ç‡å’ŒFPSé€‰é¡¹"""
        formats ,fps = self.get_camera_formats(camera_index)
        # æå–å”¯ä¸€åˆ†è¾¨ç‡å’ŒFPSé€‰é¡¹
        resolutions = [item  for item in list(formats) ] if formats else ["é»˜è®¤"] 
        fps_values = [fps]  if formats else ["é»˜è®¤"]
        # æ›´æ–°ä¸‹æ‹‰æ¡†é€‰é¡¹
        self.resolution_combo['values'] = resolutions
        self.fps_combo['values'] = fps_values
        # è®¾ç½®é»˜è®¤é€‰é¡¹
        if resolutions:
            self.resolution_combo.current(0)
        if fps_values:
            self.fps_combo.current(0)
        
        # å­˜å‚¨æ ¼å¼ä¿¡æ¯ä»¥ä¾¿åç»­ä½¿ç”¨
        self.camera_formats = formats
 

if __name__ == "__main__":
    # Add freeze support check to prevent multiple windows on startup
    from multiprocessing import freeze_support
    freeze_support()
    
    root = tk.Tk()
    fonts = tkFont.families()
    for itm in fonts:
        if "é˜¿é‡Œå·´å·´æ™®æƒ " in itm:
            font_name = itm
            break
        elif "Microsoft YaHei" in itm:
            font_name = itm
            break

    if font_name is None:
        font_name = font_name
    app = VoiceFilterApp(root)
    # Only set the protocol if the root window still exists (not destroyed during auth)
    try:
        if root.winfo_exists():
            root.protocol("WM_DELETE_WINDOW", app.on_closing)
            root.mainloop()
    except tk.TclError as e:
        # Application was destroyed during authentication, exit gracefully
        logger.error(f"Tkinter error: {e}")
        pass
